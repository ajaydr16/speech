<!DOCTYPE html>
<html>

<head>
    <title>Speech Sample</title>
    <meta charset="utf-8" />
    <link rel="stylesheet" href="style1.css">
</head>

<body style="font-family:'Helvetica Neue',Helvetica,Arial,sans-serif; font-size:13px;">
    <div id="warning">
        <h1 style="font-weight:500;">Speech Recognition Speech SDK not found
            (microsoft.cognitiveservices.speech.sdk.bundle.js missing).</h1>
    </div>
    <div id="content" style="display:none">
        <table>
            <tr>
                <td></td>
                <td><font size="20" class="header" align="center">Let's Talk</font></td>
            </tr>
            <tr>
            	<td></td>
            	<td>
                    <h1 style="font-weight:500;">Record in your voice</h1><br>
                    <p style="font-size: 20px">Itâ€™s been pretty good, pretty busy. Coming up to the end of the year.</p><br>
                </td>
            </tr>
            <tr>
                <td align="right"></td>
                <td>
                    <ul>
                    <li>    
                    <button  type="submit" id="speechsdkStartContinuousRecognition">Play</button><br></li>
                    <li>
                    <button id="speechsdkStopContinuousRecognition" disabled="disabled">STOP</button></li>
                </ul>
                </td>
            </tr>

            <tr>
                <td align="right" id="res">Result:</td>
                <td align="left">
                    <textarea id="phraseDiv" style="display: inline-block;width:400px;height:200px"></textarea>
                </td>
            </tr>

            
        </table>
    </div>

    <!-- Speech SDK REFERENCE -->
    <script src="microsoft.cognitiveservices.speech.sdk.bundle.js"></script>

    <!-- Speech Speech SDK Authorization token -->
    <script>
        // Note: Replace the URL with a valid endpoint to retrieve
        //       authorization tokens for your subscription.

        // An authorization token is a more secure method to authenticate for a browser deployment as
        // it allows the subscription keys to be kept secure on a server and a 10 minute use token to be
        // handed out to clients from an endpoint that can be protected from unauthorized access.
        var authorizationEndpoint = "token.php";

        function RequestAuthorizationToken() {
            if (authorizationEndpoint) {
                var a = new XMLHttpRequest();
                a.open("GET", authorizationEndpoint);
                a.setRequestHeader("Content-Type", "application/x-www-form-urlencoded");
                a.send("");
                a.onload = function () {
                    var token = JSON.parse(atob(this.responseText.split(".")[1]));
                    regionOptions = 'eastus';
                    authorizationToken = this.responseText;
                    key.disabled = true;
                    key.value = "using authorization token (hit F5 to refresh)";
                    console.log("Got an authorization token: " + token);
                }
            }
        }
    </script>

    <!-- Speech SDK USAGE -->
    <script>
        // On document load resolve the Speech SDK dependency
        function Initialize(onComplete) {
            if (!!window.SpeechSDK) {
                document.getElementById('content').style.display = 'block';
                document.getElementById('warning').style.display = 'none';
                onComplete(window.SpeechSDK);
            }
        }
    </script>

    <!-- Browser Hooks -->
    <script>
        var phraseDiv, statusDiv;
        var key = "ed5a027c29d34ba49738a4df17c5291e";
        var authorizationToken;
        var regionOptions = "eastus";
        var languageOptions = "en-US";
        var formatOptions = "Simple Result";
        var SpeechSDK;
        var recognizer;

        var reco;
        var sdkStartContinousRecognitionBtn, sdkStopContinousRecognitionBtn;

        var soundContext = undefined;
        try {
            var AudioContext = window.AudioContext // our preferred impl
                || window.webkitAudioContext       // fallback, mostly when on Safari
                || false;                          // could not find.

            if (AudioContext) {
                soundContext = new AudioContext();
            } else {
                alert("Audio context not supported");
            }
        }
        catch (e) {
            window.console.log("no sound context found, no audio output. " + e);
        }

        document.addEventListener("DOMContentLoaded", function () {
            createBtn = document.getElementById("createBtn");
            sdkStartContinousRecognitionBtn = document.getElementById("speechsdkStartContinuousRecognition");
            sdkStopContinousRecognitionBtn = document.getElementById("speechsdkStopContinuousRecognition");
            phraseDiv = document.getElementById("phraseDiv");
            //statusDiv = document.getElementById("statusDiv");

            // Starts continuous speech recognition.
            sdkStartContinousRecognitionBtn.addEventListener("click", function () {
                phraseDiv.innerHTML = "";
                //statusDiv.innerHTML = "";
                var lastRecognized = "";

                // If an audio file was specified, use it. Else use the microphone.
                // Depending on browser security settings, the user may be prompted to allow microphone use. Using continuous recognition allows multiple
                // phrases to be recognized from a single use authorization.
                var audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
                var speechConfig;
                if (authorizationToken) {
                    speechConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(authorizationToken, 'eastus');
                } else {
     
                    speechConfig = SpeechSDK.SpeechConfig.fromSubscription('ed5a027c29d34ba49738a4df17c5291e', 'eastus');
                }

                speechConfig.speechRecognitionLanguage = "en-US";
                reco = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);

                // Before beginning speech recognition, setup the callbacks to be invoked when an event occurs.

                // The event recognizing signals that an intermediate recognition result is received.
                // You will receive one or more recognizing events as a speech phrase is recognized, with each containing
                // more recognized speech. The event will contain the text for the recognition since the last phrase was recognized.
                reco.recognizing = function (s, e) {
                    window.console.log(e);
                   // statusDiv.innerHTML += "(recognizing) Reason: " + SpeechSDK.ResultReason[e.result.reason] + " Text: " + e.result.text + "\r\n";
                    phraseDiv.innerHTML = lastRecognized + e.result.text;
                };

                // The event recognized signals that a final recognition result is received.
                // This is the final event that a phrase has been recognized.
                // For continuous recognition, you will get one recognized event for each phrase recognized.
                reco.recognized = function (s, e) {
                    window.console.log(e);

                    // Indicates that recognizable speech was not detected, and that recognition is done.
                    if (e.result.reason === SpeechSDK.ResultReason.NoMatch) {
                        var noMatchDetail = SpeechSDK.NoMatchDetails.fromResult(e.result);
                        //statusDiv.innerHTML += "(recognized)  Reason: " + SpeechSDK.ResultReason[e.result.reason] + " NoMatchReason: " + SpeechSDK.NoMatchReason[noMatchDetail.reason] + "\r\n";
                    } else {
                        //statusDiv.innerHTML += "(recognized)  Reason: " + SpeechSDK.ResultReason[e.result.reason] + " Text: " + e.result.text + "\r\n";
                    }

                    lastRecognized += e.result.text + "\r\n";
                    phraseDiv.innerHTML = lastRecognized;
                };

                // The event signals that the service has stopped processing speech.
                // https://docs.microsoft.com/javascript/api/microsoft-cognitiveservices-speech-sdk/speechrecognitioncanceledeventargs?view=azure-node-latest
                // This can happen for two broad classes of reasons.
                // 1. An error is encountered.
                //    In this case the .errorDetails property will contain a textual representation of the error.
                // 2. No additional audio is available.
                //    Caused by the input stream being closed or reaching the end of an audio file.
                reco.canceled = function (s, e) {
                    window.console.log(e);

                    //statusDiv.innerHTML += "(cancel) Reason: " + SpeechSDK.CancellationReason[e.reason];
                    if (e.reason === SpeechSDK.CancellationReason.Error) {
                        //statusDiv.innerHTML += ": " + e.errorDetails;
                    }
                    //statusDiv.innerHTML += "\r\n";
                };

                // Signals that a new session has started with the speech service
                reco.sessionStarted = function (s, e) {
                    window.console.log(e);
                    //statusDiv.innerHTML += "(sessionStarted) SessionId: " + e.sessionId + "\r\n";
                };

                // Signals the end of a session with the speech service.
                reco.sessionStopped = function (s, e) {
                    window.console.log(e);
                    //statusDiv.innerHTML += "(sessionStopped) SessionId: " + e.sessionId + "\r\n";
                    sdkStartContinousRecognitionBtn.disabled = false;
                    sdkStopContinousRecognitionBtn.disabled = true;
                };

                // Signals that the speech service has started to detect speech.
                reco.speechStartDetected = function (s, e) {
                    window.console.log(e);
                   // statusDiv.innerHTML += "(speechStartDetected) SessionId: " + e.sessionId + "\r\n";
                };

                // Signals that the speech service has detected that speech has stopped.
                reco.speechEndDetected = function (s, e) {
                    window.console.log(e);
                    //statusDiv.innerHTML += "(speechEndDetected) SessionId: " + e.sessionId + "\r\n";
                };

                // Starts recognition
                reco.startContinuousRecognitionAsync();

                sdkStartContinousRecognitionBtn.disabled = true;
                sdkStopContinousRecognitionBtn.disabled = false;
            });

            // Stops recognition and disposes of resources.
            sdkStopContinousRecognitionBtn.addEventListener("click", function () {
                reco.stopContinuousRecognitionAsync(
                    function () {
                        reco.close();
                        reco = undefined;
                    },
                    function (err) {
                        reco.close();
                        reco = undefined;
                    });

                sdkStartContinousRecognitionBtn.disabled = false;
                sdkStopContinousRecognitionBtn.disabled = true;
            });

            Initialize(function (speechSdk) {
                SpeechSDK = speechSdk;
                sdkStartContinousRecognitionBtn.disabled = false;

                // in case we have a function for getting an authorization token, call it.
                if (typeof RequestAuthorizationToken === "function") {
                    RequestAuthorizationToken();
                }
            });
        });
    </script>
</body>

</html>